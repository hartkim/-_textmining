{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 의사록 파일(.hwp)을 크롤링하여 새 디렉토리에 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from tika import parser\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# 저장 위치 설정\n",
    "SAVE_DB_DIR = \"../data/hwp\"\n",
    "if not os.path.exists(SAVE_DB_DIR):\n",
    "    os.makedirs(SAVE_DB_DIR)\n",
    "\n",
    "# 전체 페이지 수 반환\n",
    "def get_total_pages(url):\n",
    "    resp = requests.get(url)\n",
    "    soup = BeautifulSoup(resp.content)\n",
    "    end_page = int(soup.select('.i.end > a')[-1].attrs['href'].split('=')[-1])\n",
    "    return end_page\n",
    "\n",
    "# 페이지 내 데이터 크롤링\n",
    "def crawl_page(url, page):\n",
    "    params = {\n",
    "        'pageIndex': page\n",
    "    }\n",
    "    resp = requests.get(url, params=params)\n",
    "    soup = BeautifulSoup(resp.content)\n",
    "    li_list = soup.select('.bdLine.type2 > ul > li')\n",
    "    return li_list\n",
    "\n",
    "# hwp 파일 다운로드\n",
    "def download_hwp_files(li_list, save_dir):\n",
    "    for li_item in li_list:\n",
    "        link_li = li_item.select('.fileGoupBox ul li')\n",
    "        for link in link_li:\n",
    "            if link.select_one('a').attrs['title'][-3:] == 'hwp':\n",
    "                link_url = link.select_one('a').attrs['href']\n",
    "                title = li_item.select_one('.row span a span span').text\n",
    "                download_url = 'http://www.bok.or.kr' + link_url\n",
    "                file_res = requests.get(download_url)\n",
    "                file_name = '{}.hwp'.format(title)\n",
    "                file_path = os.path.join(save_dir, file_name)\n",
    "                with open(file_path, 'wb') as f:\n",
    "                    f.write(file_res.content)\n",
    "\n",
    "# 메인 함수\n",
    "def main():\n",
    "    url = 'http://www.bok.or.kr/portal/bbs/B0000245/list.do?menuNo=200761'\n",
    "    end_page = get_total_pages(url)\n",
    "    print('총 {}페이지 까지 크롤링을 시작합니다.'.format(end_page))\n",
    "    \n",
    "    li_list = []\n",
    "    for i in range(1, end_page + 1):\n",
    "        li_list.extend(crawl_page(url, i))\n",
    "        print(f\"페이지 {i} 크롤링 성공\")\n",
    "\n",
    "    download_hwp_files(li_list, SAVE_DB_DIR)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 저장한 파일의 텍스트를 추출한 후 데이터 정의 기준에 따라 전처리 과정을 진행한 후, .csv 파일 형태로 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tika import parser\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# hwp 파일 텍스트로 변환\n",
    "def convert_hwp_to_text(source_folder, output_folder):\n",
    "    # 지정 폴더 내 파일 목록 조회 (파일만)\n",
    "    hwp_files = [f for f in listdir(source_folder) if isfile(join(source_folder, f))]\n",
    "    \n",
    "    result = []\n",
    "    for hwp in hwp_files:\n",
    "        time = re.search(r'\\((.*?)\\)', hwp).group(1)\n",
    "        hwp_filepath = os.path.join(source_folder, hwp)\n",
    "        \n",
    "        # hwp 파일 텍스트로 변환\n",
    "        parsedText = parser.from_file(hwp_filepath)[\"content\"]\n",
    "        new_dict = {\n",
    "            'time': time,\n",
    "            'text': parsedText\n",
    "        }\n",
    "        result.append(new_dict)\n",
    "\n",
    "    df = pd.DataFrame(result)\n",
    "    output_path = os.path.join(output_folder, '금통위의사록(텍스트파일).xlsx')\n",
    "\n",
    "    # DataFrame을 Excel 파일로 저장\n",
    "    df.to_excel(output_path, index=False)\n",
    "\n",
    "# 텍스트 전처리 함수\n",
    "def text_filtering(text):\n",
    "    text = re.sub(r'(\\n{2,}|- \\d+ -|―|｢|｣|[․/→←+]|^.*hwp*\\w*[A-Za-z])', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.split('6. 회의경과')[1]\n",
    "    return text\n",
    "\n",
    "# 메인 함수\n",
    "def main():\n",
    "    source_folder = \"../data/hwp/\"\n",
    "    output_folder = \"../data/\"\n",
    "    \n",
    "    # hwp 파일을 텍스트로 변환하여 Excel로 저장\n",
    "    convert_hwp_to_text(source_folder, output_folder)\n",
    "\n",
    "    # Excel 파일 읽어오기\n",
    "    minutes = pd.read_excel(os.path.join(output_folder, '금통위의사록(텍스트파일).xlsx'), usecols=[1, 2])\n",
    "    minutes['time'] = minutes['time'].astype(str)\n",
    "\n",
    "    # 날짜 추출 및 datetime으로 변환\n",
    "    date_list = []\n",
    "    for time in minutes['time']:\n",
    "        date_list.extend(re.findall(r'\\d{4}.\\d{1,2}.\\d{1,2}', time))\n",
    "    minutes['time'] = date_list\n",
    "    minutes['time'] = pd.to_datetime(minutes['time'], format='%Y.%m.%d')\n",
    "\n",
    "    # 연도가 2009~2021년인 의사록 필터링\n",
    "    minutes = minutes[(minutes['time'].dt.year >= 2009) & (minutes['time'].dt.year <= 2021)]\n",
    "    minutes.sort_values(by='time')\n",
    "\n",
    "    # 텍스트 전처리 적용\n",
    "    minutes['text'] = minutes['text'].apply(text_filtering)\n",
    "\n",
    "    # 결과를 csv 파일로 저장\n",
    "    minutes.to_csv('의사록_hwp2text_전처리(완).csv', encoding='utf-8-sig', index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
